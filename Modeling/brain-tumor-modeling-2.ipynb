{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        pass\n#         print(os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-15T18:10:42.369027Z","iopub.execute_input":"2021-09-15T18:10:42.369435Z","iopub.status.idle":"2021-09-15T18:11:42.311430Z","shell.execute_reply.started":"2021-09-15T18:10:42.369350Z","shell.execute_reply":"2021-09-15T18:11:42.310570Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys \nimport glob\nimport time\nimport re\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-09-15T18:11:42.312860Z","iopub.execute_input":"2021-09-15T18:11:42.313170Z","iopub.status.idle":"2021-09-15T18:11:44.762499Z","shell.execute_reply.started":"2021-09-15T18:11:42.313136Z","shell.execute_reply":"2021-09-15T18:11:44.761679Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data_directory =  Path('../input/processed-voxels/voxels')\n\nmri_types = ['FLAIR','T1w','T1wCE','T2w']","metadata":{"execution":{"iopub.status.busy":"2021-09-15T18:11:44.764252Z","iopub.execute_input":"2021-09-15T18:11:44.764586Z","iopub.status.idle":"2021-09-15T18:11:44.770071Z","shell.execute_reply.started":"2021-09-15T18:11:44.764551Z","shell.execute_reply":"2021-09-15T18:11:44.769092Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_labels = pd.read_csv('../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv')\n\ntrain_labels['BraTS21ID'] = train_labels['BraTS21ID'].apply(lambda x : str(x).zfill(5))\ntrain_labels['BraTS21ID'] = train_labels['BraTS21ID'].astype(str)\ntrain_labels = train_labels[~train_labels['BraTS21ID'].isin(['00109', '00123', '00709'])]\nprint(train_labels.shape)\ntrain_labels.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T18:11:44.771926Z","iopub.execute_input":"2021-09-15T18:11:44.772306Z","iopub.status.idle":"2021-09-15T18:11:44.807933Z","shell.execute_reply.started":"2021-09-15T18:11:44.772270Z","shell.execute_reply":"2021-09-15T18:11:44.806983Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"(582, 2)\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"  BraTS21ID  MGMT_value\n0     00000           1\n1     00002           1\n2     00003           0\n3     00005           1\n4     00006           1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BraTS21ID</th>\n      <th>MGMT_value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00002</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00003</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00005</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00006</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_labels.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T18:11:44.809347Z","iopub.execute_input":"2021-09-15T18:11:44.809695Z","iopub.status.idle":"2021-09-15T18:11:44.828708Z","shell.execute_reply.started":"2021-09-15T18:11:44.809658Z","shell.execute_reply":"2021-09-15T18:11:44.827773Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 582 entries, 0 to 584\nData columns (total 2 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   BraTS21ID   582 non-null    object\n 1   MGMT_value  582 non-null    int64 \ndtypes: int64(1), object(1)\nmemory usage: 13.6+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train, df_valid = train_test_split(\n    train_labels, \n    test_size=0.2, \n    random_state=42, \n    stratify=train_labels[\"MGMT_value\"],\n)\n\nprint(df_train.shape)\nprint(df_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-15T18:11:44.830267Z","iopub.execute_input":"2021-09-15T18:11:44.830884Z","iopub.status.idle":"2021-09-15T18:11:44.843649Z","shell.execute_reply.started":"2021-09-15T18:11:44.830841Z","shell.execute_reply":"2021-09-15T18:11:44.842574Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(465, 2)\n(117, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"voxel = np.load('../input/processed-voxels/voxels/FLAIR/00000.npy')\nvoxel.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-15T18:11:44.845288Z","iopub.execute_input":"2021-09-15T18:11:44.845842Z","iopub.status.idle":"2021-09-15T18:11:44.933403Z","shell.execute_reply.started":"2021-09-15T18:11:44.845790Z","shell.execute_reply":"2021-09-15T18:11:44.932130Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(64, 256, 256)"},"metadata":{}}]},{"cell_type":"code","source":"voxel = np.expand_dims(voxel, 0)\nvoxel.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-15T18:11:44.936634Z","iopub.execute_input":"2021-09-15T18:11:44.937050Z","iopub.status.idle":"2021-09-15T18:11:44.943173Z","shell.execute_reply.started":"2021-09-15T18:11:44.937005Z","shell.execute_reply":"2021-09-15T18:11:44.942066Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(1, 64, 256, 256)"},"metadata":{}}]},{"cell_type":"code","source":"mri_type = 'FLAIR'\nscan_id = '00002.npy'\ndata = np.load(data_directory.joinpath(mri_type).joinpath(scan_id))","metadata":{"execution":{"iopub.status.busy":"2021-09-15T18:11:44.945186Z","iopub.execute_input":"2021-09-15T18:11:44.945912Z","iopub.status.idle":"2021-09-15T18:11:45.031956Z","shell.execute_reply.started":"2021-09-15T18:11:44.945866Z","shell.execute_reply":"2021-09-15T18:11:45.031170Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/processed-voxels/voxels'","metadata":{"execution":{"iopub.status.busy":"2021-09-15T18:11:45.033273Z","iopub.execute_input":"2021-09-15T18:11:45.033620Z","iopub.status.idle":"2021-09-15T18:11:45.037736Z","shell.execute_reply.started":"2021-09-15T18:11:45.033583Z","shell.execute_reply":"2021-09-15T18:11:45.036834Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class MRIScanDataset(Dataset) :\n    \n    def __init__(self, paths, targets=None, mri_type=None, \n                 label_smoothing=0.01, split=\"train\", augment=False) :\n        \n        self.paths = paths\n        self.targets = targets\n        self.mri_type = mri_type\n        self.label_smoothing = label_smoothing\n        self.split = split\n        self.augment = augment\n        \n        \n    def __len__(self) :\n        return len(self.paths)\n    \n    def __getitem__(self, index) :\n        \n        scan_id = self.paths[index] + '.npy'\n        \n        if self.targets is None:\n            data = np.load(data_directory.joinpath(self.mri_type[0]).joinpath(scan_id))\n            data = np.expand_dims(data, 0)\n            \n        else:\n            if self.augment:\n                rotation = np.random.randint(0,4)\n            else:\n                rotation = 0\n                \n            data = np.load(data_directory.joinpath(self.mri_type[0]).joinpath(scan_id))\n            data = np.expand_dims(data, 0)\n            \n            \n        if self.targets is None:\n            return {\"X\": torch.tensor(data).float(), \"id\": scan_id}\n        else:\n            y = torch.tensor(abs(self.targets[index]-self.label_smoothing), dtype=torch.float)\n            return {\"X\": torch.tensor(data).float(), \"y\": y}\n               ","metadata":{"execution":{"iopub.status.busy":"2021-09-15T18:11:45.039233Z","iopub.execute_input":"2021-09-15T18:11:45.039806Z","iopub.status.idle":"2021-09-15T18:11:45.052292Z","shell.execute_reply.started":"2021-09-15T18:11:45.039766Z","shell.execute_reply":"2021-09-15T18:11:45.051392Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T18:11:45.053545Z","iopub.execute_input":"2021-09-15T18:11:45.053810Z","iopub.status.idle":"2021-09-15T18:11:45.067344Z","shell.execute_reply.started":"2021-09-15T18:11:45.053784Z","shell.execute_reply":"2021-09-15T18:11:45.066381Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"    BraTS21ID  MGMT_value\n537     00789           1\n27      00044           0\n508     00740           1\n248     00360           1\n283     00410           0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BraTS21ID</th>\n      <th>MGMT_value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>537</th>\n      <td>00789</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>00044</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>508</th>\n      <td>00740</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>248</th>\n      <td>00360</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>283</th>\n      <td>00410</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_train.loc[:,\"MRI_Type\"] = 'FLAIR'\ntrain_dataset = MRIScanDataset(\n        df_train[\"BraTS21ID\"].values, \n        df_train[\"MGMT_value\"].values, \n        df_train[\"MRI_Type\"].values,\n        augment=False)\n\ntrain_loader = DataLoader(\n        train_dataset,\n        batch_size=16,\n        shuffle=True,\n        num_workers=8,pin_memory = True )\n\n\nfor data in train_loader :\n    X1 = data['X']\n    y1 = data['y']\n    print(X1.shape)\n    print(y1.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2021-09-15T18:11:45.070533Z","iopub.execute_input":"2021-09-15T18:11:45.070820Z","iopub.status.idle":"2021-09-15T18:11:57.611563Z","shell.execute_reply.started":"2021-09-15T18:11:45.070794Z","shell.execute_reply":"2021-09-15T18:11:57.610588Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"torch.Size([16, 1, 64, 256, 256])\ntorch.Size([16])\n","output_type":"stream"}]},{"cell_type":"code","source":"class CNNModel(nn.Module):\n    def __init__(self):\n        super(CNNModel, self).__init__()\n        \n        self.conv_layer1 = self._conv_layer_set(1, 16)\n        self.conv_layer2 = self._conv_layer_set(16, 32)\n        self.conv_layer3 = self._conv_layer_set(32, 64)\n        self.fc1 = nn.Linear(6*30*30*64, 64) \n        self.fc2 = nn.Linear(64, 1)\n        self.relu = nn.LeakyReLU()\n        self.batch=nn.BatchNorm1d(64)\n        self.drop=nn.Dropout(p=0.15)        \n        \n    def _conv_layer_set(self, in_c, out_c):\n        conv_layer = nn.Sequential(\n        nn.Conv3d(in_c, out_c, kernel_size=(3, 3, 3), padding=0),\n        nn.BatchNorm3d(out_c),\n        nn.LeakyReLU(),\n        nn.MaxPool3d((2, 2, 2)),\n        nn.Dropout3d(0.2)\n        )\n        return conv_layer\n    \n\n    def forward(self, x):\n        # Set 1\n#         print(x.shape)\n        out = self.conv_layer1(x)\n        out = self.conv_layer2(out)\n        out = self.conv_layer3(out)\n        out = out.view(out.size(0), -1)\n        out = self.fc1(out)\n        out = self.relu(out)\n        out = self.batch(out)\n        out = self.drop(out)\n        out = self.fc2(out)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2021-09-15T18:22:27.767752Z","iopub.execute_input":"2021-09-15T18:22:27.768081Z","iopub.status.idle":"2021-09-15T18:22:27.778214Z","shell.execute_reply.started":"2021-09-15T18:22:27.768049Z","shell.execute_reply":"2021-09-15T18:22:27.777217Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class TrainModel:\n    \n    def __init__(self, model, device, \n                optimizer, criterion ):\n        \n        self.model = model\n        self.device = device\n        self.optimizer = optimizer\n        self.criterion = criterion\n        \n        self.best_valid_score = np.inf\n        self.n_patience = 0\n        self.lastmodel = None\n        \n    def fit(self, epochs, train_dataloader, valid_dataloader, save_path, patience):\n        \n        start_time = time.time()\n        \n        for epoch in range(1, epochs + 1):\n            \n            print(f'Running Epoch {epoch}...................')\n            \n            train_loss, train_auc = self.train(train_dataloader)\n            val_loss, val_auc = self.validation(valid_dataloader)\n            \n            print(f'For Epoch {epoch :>7d} Train Loss {train_loss : >5f} Train AUC {train_auc} Val Loss {val_loss} Val AUC {val_auc} ')\n            print(f'For Epoch {epoch :>7d} Time Taken {(time.time() - start_time)/60}')\n            \n            \n            if self.best_valid_score > val_loss: \n                \n                self.save_model(epoch, save_path, val_loss, val_auc)\n                print(f'AUC Improved from {self.best_valid_score :4f} to {val_loss}. Saved model to {self.lastmodel}')\n                \n                #updating the lossed\n                self.best_valid_score = val_loss\n                self.n_patience = 0\n            else:\n                self.n_patience += 1\n            \n            if self.n_patience >= patience:\n                print(f\"\\nValid auc didn't improve last {patience} epochs.\")\n                break\n            \n            \n            \n    def train(self, train_dataloader) :\n        '''\n        For Training the model.\n        We will be calculating batch wise loss and \n        finally calcualting auc on the overall y\n        '''\n    \n        self.model.train()\n        sum_loss = 0\n        y_all = []\n        output_all = []\n        start_time = time.time()\n\n        for batch, data in enumerate(train_dataloader) :\n\n            X = data['X'].to(self.device)\n            y = data['y'].to(self.device)\n\n            self.optimizer.zero_grad()     #clearning the accumulated gradients\n            pred = self.model(X).squeeze(1)           #make the prediction\n            loss = self.criterion(pred, y) #calcualte the loss\n            loss.backward()           #backpropagation\n            self.optimizer.step()          #update weights\n\n            sum_loss += loss.detach().item()\n            y_all.extend(data['y'].tolist()) #save all y values to y_val\n            output_all.extend(torch.sigmoid(pred).tolist())  #save all pred to output all\n\n            #print peformance\n            if batch % 20 == 0 :\n                time_taken = (time.time() - start_time)\n                start_time = time.time()\n                print(f'Train Batch {batch + 1 :>7d} Loss : {sum_loss/(batch +1)} Time Taken : {time_taken/60} ')\n\n        y_all = [1 if x > 0.5 else 0 for x in y_all]\n        train_auc = roc_auc_score(y_all, output_all)\n\n        return sum_loss/len(train_dataloader) , train_auc\n    \n    \n    \n    def validation(self, val_dataloader) :\n    \n        self.model.eval()\n        sum_loss = 0\n        y_all = []\n        output_all = []\n\n        for batch, data in enumerate(val_dataloader) :\n\n            with torch.no_grad() :\n\n                X_val = data['X'].to(self.device)\n                y_val = data['y'].to(self.device)\n\n                pred = self.model(X_val).squeeze(1)   #make the prediction\n                loss = self.criterion(pred, y_val) #calcualte the loss\n\n                sum_loss += loss.detach().item()\n                y_all.extend(data['y'].tolist()) #save all y values to y_val\n                output_all.extend(torch.sigmoid(pred).tolist())  #save all pred to output all\n\n                #print peformance\n                if batch % 20 == 0 :\n                    print(f'Test Batch {batch + 1 :>7d} Loss : {sum_loss/(batch +1)}')\n\n        y_all = [1 if x > 0.5 else 0 for x in y_all]\n        val_auc = roc_auc_score(y_all, output_all)\n\n        return sum_loss/len(val_dataloader) , val_auc\n\n            \n    def save_model(self, n_epoch, save_path, loss, auc):\n        \n        self.lastmodel = f\"{save_path}_loss{loss:.3f}_auc{auc:.3f}.pth\"\n        torch.save(self.model.state_dict(), self.lastmodel)\n       ","metadata":{"execution":{"iopub.status.busy":"2021-09-15T18:22:28.377892Z","iopub.execute_input":"2021-09-15T18:22:28.378227Z","iopub.status.idle":"2021-09-15T18:22:28.396676Z","shell.execute_reply.started":"2021-09-15T18:22:28.378178Z","shell.execute_reply":"2021-09-15T18:22:28.395843Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#train the model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef train_mri_type(df_train, df_valid, mri_type):\n    \n    #creating data based on selected mri_type\n    if mri_type==\"all\":\n        train_list = []\n        valid_list = []\n        for mri_type in mri_types:\n            df_train.loc[:,\"MRI_Type\"] = mri_type\n            train_list.append(df_train.copy())\n            df_valid.loc[:,\"MRI_Type\"] = mri_type\n            valid_list.append(df_valid.copy())\n\n        df_train = pd.concat(train_list)\n        df_valid = pd.concat(valid_list)\n        \n    else:\n        df_train.loc[:,\"MRI_Type\"] = mri_type\n        df_valid.loc[:,\"MRI_Type\"] = mri_type\n\n    print(df_train.shape, df_valid.shape)\n    display(df_train.head())\n    \n    #train dataset\n    train_dataset = MRIScanDataset(\n        df_train[\"BraTS21ID\"].values, \n        df_train[\"MGMT_value\"].values, \n        df_train[\"MRI_Type\"].values,\n        augment=False)\n    \n    #valid dataset\n    valid_dataset = MRIScanDataset(\n        df_valid[\"BraTS21ID\"].values, \n        df_valid[\"MGMT_value\"].values,\n        df_valid[\"MRI_Type\"].values)\n    \n    #train dataloader\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=8,\n        shuffle=True,\n    drop_last=True)\n\n    valid_loader = DataLoader(\n        valid_dataset, \n        batch_size=8,\n        shuffle=False,\n    drop_last=True)\n    \n    #load model\n    model = CNNModel()\n    model.to(device)\n    \n    #define optimizer & criterion\n    criterion = F.binary_cross_entropy_with_logits\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n    \n\n    trainer = TrainModel(model, device, \n                    optimizer,criterion)\n\n    history = trainer.fit(epochs= 10, train_dataloader= train_loader, valid_dataloader= valid_loader, save_path= f\"{mri_type}\", patience= 6)\n    \n    return trainer.lastmodel\n","metadata":{"execution":{"iopub.status.busy":"2021-09-15T18:36:01.164671Z","iopub.execute_input":"2021-09-15T18:36:01.165063Z","iopub.status.idle":"2021-09-15T18:36:01.176165Z","shell.execute_reply.started":"2021-09-15T18:36:01.165029Z","shell.execute_reply":"2021-09-15T18:36:01.175267Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"print(device)","metadata":{"execution":{"iopub.status.busy":"2021-09-15T18:36:01.916347Z","iopub.execute_input":"2021-09-15T18:36:01.916673Z","iopub.status.idle":"2021-09-15T18:36:01.921032Z","shell.execute_reply.started":"2021-09-15T18:36:01.916644Z","shell.execute_reply":"2021-09-15T18:36:01.920149Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"modelfiles = None\n\nif not modelfiles:\n    modelfiles = [train_mri_type(df_train, df_valid, m) for m in ['T2w', 'FLAIR', 'T1wCE', 'T1w']]\n    print(modelfiles)","metadata":{"execution":{"iopub.status.busy":"2021-09-15T18:36:03.686639Z","iopub.execute_input":"2021-09-15T18:36:03.686970Z","iopub.status.idle":"2021-09-15T19:07:55.722480Z","shell.execute_reply.started":"2021-09-15T18:36:03.686939Z","shell.execute_reply":"2021-09-15T19:07:55.720322Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"(465, 3) (117, 3)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"    BraTS21ID  MGMT_value MRI_Type\n537     00789           1      T2w\n27      00044           0      T2w\n508     00740           1      T2w\n248     00360           1      T2w\n283     00410           0      T2w","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BraTS21ID</th>\n      <th>MGMT_value</th>\n      <th>MRI_Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>537</th>\n      <td>00789</td>\n      <td>1</td>\n      <td>T2w</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>00044</td>\n      <td>0</td>\n      <td>T2w</td>\n    </tr>\n    <tr>\n      <th>508</th>\n      <td>00740</td>\n      <td>1</td>\n      <td>T2w</td>\n    </tr>\n    <tr>\n      <th>248</th>\n      <td>00360</td>\n      <td>1</td>\n      <td>T2w</td>\n    </tr>\n    <tr>\n      <th>283</th>\n      <td>00410</td>\n      <td>0</td>\n      <td>T2w</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Running Epoch 1...................\nTrain Batch       1 Loss : 0.7419384717941284 Time Taken : 0.012706617514292399 \nTrain Batch      21 Loss : 0.9331856994401841 Time Taken : 0.234485658009847 \nTrain Batch      41 Loss : 0.8745185747379209 Time Taken : 0.23652841250101725 \nTest Batch       1 Loss : 0.6282409429550171\nFor Epoch       1 Train Loss 0.822478 Train AUC 0.532935916542474 Val Loss 0.6924331571374621 Val AUC 0.542948717948718 \nFor Epoch       1 Time Taken 0.7594892501831054\nAUC Improved from  inf to 0.6924331571374621. Saved model to T2w_loss0.692_auc0.543.pth\nRunning Epoch 2...................\nTrain Batch       1 Loss : 0.811424732208252 Time Taken : 0.011146438121795655 \nTrain Batch      21 Loss : 0.7513163032985869 Time Taken : 0.23562888701756796 \nTrain Batch      41 Loss : 0.7253739121483593 Time Taken : 0.23792458375295003 \nTest Batch       1 Loss : 0.6169658899307251\nFor Epoch       2 Train Loss 0.723236 Train AUC 0.5249241196953616 Val Loss 0.6697958069188255 Val AUC 0.6596153846153846 \nFor Epoch       2 Time Taken 1.5246731678644816\nAUC Improved from 0.692433 to 0.6697958069188255. Saved model to T2w_loss0.670_auc0.660.pth\nRunning Epoch 3...................\nTrain Batch       1 Loss : 0.8648116588592529 Time Taken : 0.012068458398183187 \nTrain Batch      21 Loss : 0.692978682972136 Time Taken : 0.23941569328308104 \nTrain Batch      41 Loss : 0.6864986230687398 Time Taken : 0.23744982481002808 \nTest Batch       1 Loss : 0.5576788187026978\nFor Epoch       3 Train Loss 0.690426 Train AUC 0.5849952516619183 Val Loss 0.6631740161350795 Val AUC 0.6647435897435898 \nFor Epoch       3 Time Taken 2.2937873244285583\nAUC Improved from 0.669796 to 0.6631740161350795. Saved model to T2w_loss0.663_auc0.665.pth\nRunning Epoch 4...................\nTrain Batch       1 Loss : 0.8902887105941772 Time Taken : 0.012032059828440349 \nTrain Batch      21 Loss : 0.7076258489063808 Time Taken : 0.2363655169804891 \nTrain Batch      41 Loss : 0.7082067190147028 Time Taken : 0.2373303731282552 \nTest Batch       1 Loss : 0.6123819351196289\nFor Epoch       4 Train Loss 0.699527 Train AUC 0.5395864381520119 Val Loss 0.6602634957858494 Val AUC 0.7141025641025641 \nFor Epoch       4 Time Taken 3.063895281155904\nAUC Improved from 0.663174 to 0.6602634957858494. Saved model to T2w_loss0.660_auc0.714.pth\nRunning Epoch 5...................\nTrain Batch       1 Loss : 0.7117445468902588 Time Taken : 0.011410343647003173 \nTrain Batch      21 Loss : 0.6572680586860293 Time Taken : 0.23963812987009683 \nTrain Batch      41 Loss : 0.6733162286804943 Time Taken : 0.23680519660313923 \nTest Batch       1 Loss : 0.6298574805259705\nFor Epoch       5 Train Loss 0.665933 Train AUC 0.6261549925484352 Val Loss 0.6654103994369507 Val AUC 0.6753205128205128 \nFor Epoch       5 Time Taken 3.838447634379069\nRunning Epoch 6...................\nTrain Batch       1 Loss : 0.8663825988769531 Time Taken : 0.012122809886932373 \nTrain Batch      21 Loss : 0.6924440917514619 Time Taken : 0.23876630862553913 \nTrain Batch      41 Loss : 0.6777007121865343 Time Taken : 0.2376858949661255 \nTest Batch       1 Loss : 0.57038414478302\nFor Epoch       6 Train Loss 0.680092 Train AUC 0.5962422955887008 Val Loss 0.6548920231206077 Val AUC 0.7060897435897436 \nFor Epoch       6 Time Taken 4.60792727470398\nAUC Improved from 0.660263 to 0.6548920231206077. Saved model to T2w_loss0.655_auc0.706.pth\nRunning Epoch 7...................\nTrain Batch       1 Loss : 0.6605982184410095 Time Taken : 0.011445701122283936 \nTrain Batch      21 Loss : 0.6670465355827695 Time Taken : 0.2343411644299825 \nTrain Batch      41 Loss : 0.6729333298962291 Time Taken : 0.23826042016347249 \nTest Batch       1 Loss : 0.6613444089889526\nFor Epoch       7 Train Loss 0.663975 Train AUC 0.6322093889716841 Val Loss 0.6703865485531944 Val AUC 0.6480769230769231 \nFor Epoch       7 Time Taken 5.380383622646332\nRunning Epoch 8...................\nTrain Batch       1 Loss : 0.6592392921447754 Time Taken : 0.011874385674794515 \nTrain Batch      21 Loss : 0.6495408756392342 Time Taken : 0.23938517570495604 \nTrain Batch      41 Loss : 0.6621693081972075 Time Taken : 0.2385425567626953 \nTest Batch       1 Loss : 0.6145883202552795\nFor Epoch       8 Train Loss 0.652452 Train AUC 0.6587155279965737 Val Loss 0.6681768723896572 Val AUC 0.6358974358974359 \nFor Epoch       8 Time Taken 6.147869400183359\nRunning Epoch 9...................\nTrain Batch       1 Loss : 0.4856964349746704 Time Taken : 0.011470150947570801 \nTrain Batch      21 Loss : 0.674273126182102 Time Taken : 0.23843411207199097 \nTrain Batch      41 Loss : 0.6419150291419611 Time Taken : 0.23618293205897015 \nTest Batch       1 Loss : 0.5603187084197998\nFor Epoch       9 Train Loss 0.645467 Train AUC 0.6694485842026825 Val Loss 0.6593204992158073 Val AUC 0.651602564102564 \nFor Epoch       9 Time Taken 6.911490869522095\nRunning Epoch 10...................\nTrain Batch       1 Loss : 0.7854203581809998 Time Taken : 0.011322406927744548 \nTrain Batch      21 Loss : 0.5905162592728933 Time Taken : 0.23811566829681396 \nTrain Batch      41 Loss : 0.5945737616318029 Time Taken : 0.23884514967600504 \nTest Batch       1 Loss : 0.6001189351081848\nFor Epoch      10 Train Loss 0.602359 Train AUC 0.7462525371022104 Val Loss 0.681252509355545 Val AUC 0.6006410256410256 \nFor Epoch      10 Time Taken 7.684928099314372\n(465, 3) (117, 3)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"    BraTS21ID  MGMT_value MRI_Type\n537     00789           1    FLAIR\n27      00044           0    FLAIR\n508     00740           1    FLAIR\n248     00360           1    FLAIR\n283     00410           0    FLAIR","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BraTS21ID</th>\n      <th>MGMT_value</th>\n      <th>MRI_Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>537</th>\n      <td>00789</td>\n      <td>1</td>\n      <td>FLAIR</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>00044</td>\n      <td>0</td>\n      <td>FLAIR</td>\n    </tr>\n    <tr>\n      <th>508</th>\n      <td>00740</td>\n      <td>1</td>\n      <td>FLAIR</td>\n    </tr>\n    <tr>\n      <th>248</th>\n      <td>00360</td>\n      <td>1</td>\n      <td>FLAIR</td>\n    </tr>\n    <tr>\n      <th>283</th>\n      <td>00410</td>\n      <td>0</td>\n      <td>FLAIR</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Running Epoch 1...................\nTrain Batch       1 Loss : 0.8240934610366821 Time Taken : 0.012363346417744954 \nTrain Batch      21 Loss : 1.019320206982749 Time Taken : 0.2835907697677612 \nTrain Batch      41 Loss : 0.896081475222983 Time Taken : 0.28166722853978476 \nTest Batch       1 Loss : 0.6079650521278381\nFor Epoch       1 Train Loss 0.861728 Train AUC 0.47554023845007454 Val Loss 0.6660994589328766 Val AUC 0.6557692307692308 \nFor Epoch       1 Time Taken 0.961834458510081\nAUC Improved from  inf to 0.6660994589328766. Saved model to FLAIR_loss0.666_auc0.656.pth\nRunning Epoch 2...................\nTrain Batch       1 Loss : 0.7887693643569946 Time Taken : 0.01188277800877889 \nTrain Batch      21 Loss : 0.7139572813397362 Time Taken : 0.24015438556671143 \nTrain Batch      41 Loss : 0.7180274361517371 Time Taken : 0.23812594413757324 \nTest Batch       1 Loss : 0.6212069988250732\nFor Epoch       2 Train Loss 0.711594 Train AUC 0.5261922503725782 Val Loss 0.6584216015679496 Val AUC 0.7054487179487179 \nFor Epoch       2 Time Taken 1.738593908150991\nAUC Improved from 0.666099 to 0.6584216015679496. Saved model to FLAIR_loss0.658_auc0.705.pth\nRunning Epoch 3...................\nTrain Batch       1 Loss : 1.011499285697937 Time Taken : 0.011466658115386963 \nTrain Batch      21 Loss : 0.704150534811474 Time Taken : 0.2352121909459432 \nTrain Batch      41 Loss : 0.7072193535362802 Time Taken : 0.23842575550079345 \nTest Batch       1 Loss : 0.6513694524765015\nFor Epoch       3 Train Loss 0.706220 Train AUC 0.527924739195231 Val Loss 0.6791098415851593 Val AUC 0.6064102564102564 \nFor Epoch       3 Time Taken 2.514374089241028\nRunning Epoch 4...................\nTrain Batch       1 Loss : 0.6473002433776855 Time Taken : 0.011789170900980632 \nTrain Batch      21 Loss : 0.7047665147554307 Time Taken : 0.2387731711069743 \nTrain Batch      41 Loss : 0.6946508070317711 Time Taken : 0.24019521872202557 \nTest Batch       1 Loss : 0.6179439425468445\nFor Epoch       4 Train Loss 0.691740 Train AUC 0.5536698956780923 Val Loss 0.6881753972598484 Val AUC 0.5455128205128205 \nFor Epoch       4 Time Taken 3.2858477075894674\nRunning Epoch 5...................\nTrain Batch       1 Loss : 0.765792965888977 Time Taken : 0.011478130022684734 \nTrain Batch      21 Loss : 0.6766599814097086 Time Taken : 0.239342733224233 \nTrain Batch      41 Loss : 0.6926826776527777 Time Taken : 0.237703537940979 \nTest Batch       1 Loss : 0.5826433300971985\nFor Epoch       5 Train Loss 0.691907 Train AUC 0.5638046291641062 Val Loss 0.6640474668570927 Val AUC 0.6753205128205128 \nFor Epoch       5 Time Taken 4.0562601010004675\nRunning Epoch 6...................\nTrain Batch       1 Loss : 0.4970169961452484 Time Taken : 0.011568907896677654 \nTrain Batch      21 Loss : 0.6813273160230546 Time Taken : 0.23718356291453044 \nTrain Batch      41 Loss : 0.6722733036773961 Time Taken : 0.24054772059122723 \nTest Batch       1 Loss : 0.5050590634346008\nFor Epoch       6 Train Loss 0.678783 Train AUC 0.6095935050183416 Val Loss 0.6733627872807639 Val AUC 0.632051282051282 \nFor Epoch       6 Time Taken 4.823386724789938\nRunning Epoch 7...................\nTrain Batch       1 Loss : 0.5621765851974487 Time Taken : 0.011440086364746093 \nTrain Batch      21 Loss : 0.6534833709398905 Time Taken : 0.2382742444674174 \nTrain Batch      41 Loss : 0.6643459288085379 Time Taken : 0.23878626426060995 \nTest Batch       1 Loss : 0.6080822944641113\nFor Epoch       7 Train Loss 0.671971 Train AUC 0.6205984768076271 Val Loss 0.6641003106321607 Val AUC 0.6705128205128206 \nFor Epoch       7 Time Taken 5.599589172999064\nRunning Epoch 8...................\nTrain Batch       1 Loss : 0.6810040473937988 Time Taken : 0.011092805862426757 \nTrain Batch      21 Loss : 0.6373155996913001 Time Taken : 0.23357303937276205 \nTrain Batch      41 Loss : 0.6514832668188142 Time Taken : 0.2365845998128255 \nTest Batch       1 Loss : 0.5594871044158936\nFor Epoch       8 Train Loss 0.655701 Train AUC 0.6581382790533118 Val Loss 0.6534501654761178 Val AUC 0.6836538461538462 \nFor Epoch       8 Time Taken 6.363761917750041\nAUC Improved from 0.658422 to 0.6534501654761178. Saved model to FLAIR_loss0.653_auc0.684.pth\nRunning Epoch 9...................\nTrain Batch       1 Loss : 0.5543304085731506 Time Taken : 0.01121368408203125 \nTrain Batch      21 Loss : 0.6640226471991766 Time Taken : 0.23698790868123373 \nTrain Batch      41 Loss : 0.6486998963646773 Time Taken : 0.23887314796447753 \nTest Batch       1 Loss : 0.6006072759628296\nFor Epoch       9 Train Loss 0.652733 Train AUC 0.6669459806714709 Val Loss 0.651411350284304 Val AUC 0.6900641025641026 \nFor Epoch       9 Time Taken 7.138006027539571\nAUC Improved from 0.653450 to 0.651411350284304. Saved model to FLAIR_loss0.651_auc0.690.pth\nRunning Epoch 10...................\nTrain Batch       1 Loss : 0.7975296974182129 Time Taken : 0.01260685920715332 \nTrain Batch      21 Loss : 0.6552458774475824 Time Taken : 0.23442387183507282 \nTrain Batch      41 Loss : 0.6506865736914844 Time Taken : 0.23709062337875367 \nTest Batch       1 Loss : 0.5830819606781006\nFor Epoch      10 Train Loss 0.651400 Train AUC 0.6581568999869655 Val Loss 0.649256591285978 Val AUC 0.703525641025641 \nFor Epoch      10 Time Taken 7.904422982533773\nAUC Improved from 0.651411 to 0.649256591285978. Saved model to FLAIR_loss0.649_auc0.704.pth\n(465, 3) (117, 3)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"    BraTS21ID  MGMT_value MRI_Type\n537     00789           1    T1wCE\n27      00044           0    T1wCE\n508     00740           1    T1wCE\n248     00360           1    T1wCE\n283     00410           0    T1wCE","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BraTS21ID</th>\n      <th>MGMT_value</th>\n      <th>MRI_Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>537</th>\n      <td>00789</td>\n      <td>1</td>\n      <td>T1wCE</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>00044</td>\n      <td>0</td>\n      <td>T1wCE</td>\n    </tr>\n    <tr>\n      <th>508</th>\n      <td>00740</td>\n      <td>1</td>\n      <td>T1wCE</td>\n    </tr>\n    <tr>\n      <th>248</th>\n      <td>00360</td>\n      <td>1</td>\n      <td>T1wCE</td>\n    </tr>\n    <tr>\n      <th>283</th>\n      <td>00410</td>\n      <td>0</td>\n      <td>T1wCE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Running Epoch 1...................\nTrain Batch       1 Loss : 0.6425114274024963 Time Taken : 0.018671456972757974 \nTrain Batch      21 Loss : 1.1026231674920945 Time Taken : 0.32405279874801635 \nTrain Batch      41 Loss : 0.9532143713497534 Time Taken : 0.3180151621500651 \nTest Batch       1 Loss : 0.7387741804122925\nFor Epoch       1 Train Loss 0.899050 Train AUC 0.509152188890751 Val Loss 0.7054603866168431 Val AUC 0.4342948717948718 \nFor Epoch       1 Time Taken 1.0644724170366924\nAUC Improved from  inf to 0.7054603866168431. Saved model to T1wCE_loss0.705_auc0.434.pth\nRunning Epoch 2...................\nTrain Batch       1 Loss : 0.7883315086364746 Time Taken : 0.011957859992980957 \nTrain Batch      21 Loss : 0.722917358080546 Time Taken : 0.23712121645609538 \nTrain Batch      41 Loss : 0.7004657358658023 Time Taken : 0.23841469685236613 \nTest Batch       1 Loss : 0.6065022945404053\nFor Epoch       2 Train Loss 0.706465 Train AUC 0.577304806062976 Val Loss 0.6885048917361668 Val AUC 0.5625000000000001 \nFor Epoch       2 Time Taken 1.8373754858970641\nAUC Improved from 0.705460 to 0.6885048917361668. Saved model to T1wCE_loss0.689_auc0.563.pth\nRunning Epoch 3...................\nTrain Batch       1 Loss : 0.7561030387878418 Time Taken : 0.011871822675069173 \nTrain Batch      21 Loss : 0.7056579078946795 Time Taken : 0.237943696975708 \nTrain Batch      41 Loss : 0.7046075288842364 Time Taken : 0.2365813414255778 \nTest Batch       1 Loss : 0.7001069784164429\nFor Epoch       3 Train Loss 0.701496 Train AUC 0.5566877794336811 Val Loss 0.6904897860118321 Val AUC 0.5490384615384616 \nFor Epoch       3 Time Taken 2.6081146478652952\nRunning Epoch 4...................\nTrain Batch       1 Loss : 0.6380658149719238 Time Taken : 0.011253345012664794 \nTrain Batch      21 Loss : 0.7010614701679775 Time Taken : 0.23639407952626545 \nTrain Batch      41 Loss : 0.6873087228798285 Time Taken : 0.23759799400965373 \nTest Batch       1 Loss : 0.635086715221405\nFor Epoch       4 Train Loss 0.691637 Train AUC 0.5636556616948774 Val Loss 0.6772804728576115 Val AUC 0.6522435897435896 \nFor Epoch       4 Time Taken 3.372739255428314\nAUC Improved from 0.688505 to 0.6772804728576115. Saved model to T1wCE_loss0.677_auc0.652.pth\nRunning Epoch 5...................\nTrain Batch       1 Loss : 0.7637296319007874 Time Taken : 0.011057209968566895 \nTrain Batch      21 Loss : 0.6837276702835446 Time Taken : 0.2370345155398051 \nTrain Batch      41 Loss : 0.674488877377859 Time Taken : 0.23873275518417358 \nTest Batch       1 Loss : 0.5810892581939697\nFor Epoch       5 Train Loss 0.672019 Train AUC 0.6001340707223061 Val Loss 0.6735325029918126 Val AUC 0.6483974358974359 \nFor Epoch       5 Time Taken 4.145229188601176\nAUC Improved from 0.677280 to 0.6735325029918126. Saved model to T1wCE_loss0.674_auc0.648.pth\nRunning Epoch 6...................\nTrain Batch       1 Loss : 0.6170215606689453 Time Taken : 0.011494632562001545 \nTrain Batch      21 Loss : 0.6871846375011262 Time Taken : 0.2372350017229716 \nTrain Batch      41 Loss : 0.6749615945467135 Time Taken : 0.23343193531036377 \nTest Batch       1 Loss : 0.5892497897148132\nFor Epoch       6 Train Loss 0.664421 Train AUC 0.639293894195855 Val Loss 0.6770592374461037 Val AUC 0.6217948717948718 \nFor Epoch       6 Time Taken 4.9160547415415445\nRunning Epoch 7...................\nTrain Batch       1 Loss : 0.7159062027931213 Time Taken : 0.012058444817860921 \nTrain Batch      21 Loss : 0.6444007328578404 Time Taken : 0.23427808284759521 \nTrain Batch      41 Loss : 0.6603661920966172 Time Taken : 0.23849897782007853 \nTest Batch       1 Loss : 0.5667260885238647\nFor Epoch       7 Train Loss 0.658050 Train AUC 0.6531110283159463 Val Loss 0.6860846281051636 Val AUC 0.5842948717948718 \nFor Epoch       7 Time Taken 5.678614636262258\nRunning Epoch 8...................\nTrain Batch       1 Loss : 0.5796898603439331 Time Taken : 0.011871552467346192 \nTrain Batch      21 Loss : 0.6258362432320913 Time Taken : 0.23789719740549722 \nTrain Batch      41 Loss : 0.6266690819728665 Time Taken : 0.2374704877535502 \nTest Batch       1 Loss : 0.5528856515884399\nFor Epoch       8 Train Loss 0.634270 Train AUC 0.693591654247392 Val Loss 0.6781419473034995 Val AUC 0.6028846153846155 \nFor Epoch       8 Time Taken 6.451522095998128\nRunning Epoch 9...................\nTrain Batch       1 Loss : 0.4448510408401489 Time Taken : 0.011884629726409912 \nTrain Batch      21 Loss : 0.6373885557765052 Time Taken : 0.2346285621325175 \nTrain Batch      41 Loss : 0.6311363672337881 Time Taken : 0.23745350042978922 \nTest Batch       1 Loss : 0.6131085157394409\nFor Epoch       9 Train Loss 0.618010 Train AUC 0.725875558867362 Val Loss 0.709058438028608 Val AUC 0.5291666666666667 \nFor Epoch       9 Time Taken 7.216477644443512\nRunning Epoch 10...................\nTrain Batch       1 Loss : 0.6873375177383423 Time Taken : 0.011378832658131917 \nTrain Batch      21 Loss : 0.6188814072381883 Time Taken : 0.23893165985743206 \nTrain Batch      41 Loss : 0.6124233043775326 Time Taken : 0.23805410861968995 \nTest Batch       1 Loss : 0.4868444502353668\nFor Epoch      10 Train Loss 0.628328 Train AUC 0.711941132637854 Val Loss 0.6873104082686561 Val AUC 0.5878205128205128 \nFor Epoch      10 Time Taken 7.985920894145965\n(465, 3) (117, 3)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"    BraTS21ID  MGMT_value MRI_Type\n537     00789           1      T1w\n27      00044           0      T1w\n508     00740           1      T1w\n248     00360           1      T1w\n283     00410           0      T1w","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BraTS21ID</th>\n      <th>MGMT_value</th>\n      <th>MRI_Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>537</th>\n      <td>00789</td>\n      <td>1</td>\n      <td>T1w</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>00044</td>\n      <td>0</td>\n      <td>T1w</td>\n    </tr>\n    <tr>\n      <th>508</th>\n      <td>00740</td>\n      <td>1</td>\n      <td>T1w</td>\n    </tr>\n    <tr>\n      <th>248</th>\n      <td>00360</td>\n      <td>1</td>\n      <td>T1w</td>\n    </tr>\n    <tr>\n      <th>283</th>\n      <td>00410</td>\n      <td>0</td>\n      <td>T1w</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Running Epoch 1...................\nTrain Batch       1 Loss : 0.7350436449050903 Time Taken : 0.02062479257583618 \nTrain Batch      21 Loss : 0.9648349341892061 Time Taken : 0.33114058574040733 \nTrain Batch      41 Loss : 0.903342340050674 Time Taken : 0.332040810585022 \nTest Batch       1 Loss : 0.6534786820411682\nFor Epoch       1 Train Loss 0.869699 Train AUC 0.509915647170549 Val Loss 0.6808912839208331 Val AUC 0.5958333333333333 \nFor Epoch       1 Time Taken 1.1046905318895976\nAUC Improved from  inf to 0.6808912839208331. Saved model to T1w_loss0.681_auc0.596.pth\nRunning Epoch 2...................\nTrain Batch       1 Loss : 0.5835310220718384 Time Taken : 0.012427397569020589 \nTrain Batch      21 Loss : 0.7399781431470599 Time Taken : 0.2705345312754313 \nTrain Batch      41 Loss : 0.7244357059641582 Time Taken : 0.28838709990183514 \nTest Batch       1 Loss : 0.6939533352851868\nFor Epoch       2 Train Loss 0.710550 Train AUC 0.52172131910694 Val Loss 0.7137791727270398 Val AUC 0.42243589743589743 \nFor Epoch       2 Time Taken 2.073589007059733\nRunning Epoch 3...................\nTrain Batch       1 Loss : 0.5994436740875244 Time Taken : 0.01148373285929362 \nTrain Batch      21 Loss : 0.6967345646449498 Time Taken : 0.23869927724202475 \nTrain Batch      41 Loss : 0.696936284623495 Time Taken : 0.2380957285563151 \nTest Batch       1 Loss : 0.65656578540802\nFor Epoch       3 Train Loss 0.688173 Train AUC 0.5734910581222057 Val Loss 0.6788137299673898 Val AUC 0.6221153846153846 \nFor Epoch       3 Time Taken 2.8498945315678914\nAUC Improved from 0.680891 to 0.6788137299673898. Saved model to T1w_loss0.679_auc0.622.pth\nRunning Epoch 4...................\nTrain Batch       1 Loss : 0.7694058418273926 Time Taken : 0.011911678314208984 \nTrain Batch      21 Loss : 0.7050412325632005 Time Taken : 0.23874794244766234 \nTrain Batch      41 Loss : 0.7014214352863591 Time Taken : 0.23690768480300903 \nTest Batch       1 Loss : 0.6401442289352417\nFor Epoch       4 Train Loss 0.702397 Train AUC 0.5242734724292101 Val Loss 0.6725677336965289 Val AUC 0.6339743589743589 \nFor Epoch       4 Time Taken 3.6311868985493976\nAUC Improved from 0.678814 to 0.6725677336965289. Saved model to T1w_loss0.673_auc0.634.pth\nRunning Epoch 5...................\nTrain Batch       1 Loss : 0.7548874020576477 Time Taken : 0.011785900592803955 \nTrain Batch      21 Loss : 0.6848600109418234 Time Taken : 0.2369369586308797 \nTrain Batch      41 Loss : 0.6948777742502166 Time Taken : 0.23896979888280231 \nTest Batch       1 Loss : 0.6661396026611328\nFor Epoch       5 Train Loss 0.687497 Train AUC 0.5698936744688379 Val Loss 0.6871331334114075 Val AUC 0.532051282051282 \nFor Epoch       5 Time Taken 4.409554938475291\nRunning Epoch 6...................\nTrain Batch       1 Loss : 0.6786037683486938 Time Taken : 0.011799705028533936 \nTrain Batch      21 Loss : 0.7098236538115001 Time Taken : 0.23809411923090618 \nTrain Batch      41 Loss : 0.6783066261105422 Time Taken : 0.23730833530426027 \nTest Batch       1 Loss : 0.6110635995864868\nFor Epoch       6 Train Loss 0.684461 Train AUC 0.577304806062976 Val Loss 0.6657038629055023 Val AUC 0.6410256410256411 \nFor Epoch       6 Time Taken 5.181349217891693\nAUC Improved from 0.672568 to 0.6657038629055023. Saved model to T1w_loss0.666_auc0.641.pth\nRunning Epoch 7...................\nTrain Batch       1 Loss : 0.6858829855918884 Time Taken : 0.0118376890818278 \nTrain Batch      21 Loss : 0.70187547093346 Time Taken : 0.23636237780253092 \nTrain Batch      41 Loss : 0.6792569727432437 Time Taken : 0.23975183169047037 \nTest Batch       1 Loss : 0.6249343752861023\nFor Epoch       7 Train Loss 0.685130 Train AUC 0.5839232488822653 Val Loss 0.6705660053661892 Val AUC 0.6378205128205128 \nFor Epoch       7 Time Taken 5.959232807159424\nRunning Epoch 8...................\nTrain Batch       1 Loss : 0.6517781019210815 Time Taken : 0.011874830722808838 \nTrain Batch      21 Loss : 0.6808513516471499 Time Taken : 0.2392383058865865 \nTrain Batch      41 Loss : 0.6792594194412231 Time Taken : 0.2363016168276469 \nTest Batch       1 Loss : 0.6227976679801941\nFor Epoch       8 Train Loss 0.682231 Train AUC 0.5893432396700371 Val Loss 0.6746911406517029 Val AUC 0.6243589743589744 \nFor Epoch       8 Time Taken 6.729592299461364\nRunning Epoch 9...................\nTrain Batch       1 Loss : 0.5206091403961182 Time Taken : 0.012190282344818115 \nTrain Batch      21 Loss : 0.6680866934004284 Time Taken : 0.23609623511632283 \nTrain Batch      41 Loss : 0.6573084360215722 Time Taken : 0.2394618590672811 \nTest Batch       1 Loss : 0.6117959022521973\nFor Epoch       9 Train Loss 0.658985 Train AUC 0.6509133567957097 Val Loss 0.7457089296409062 Val AUC 0.45929487179487183 \nFor Epoch       9 Time Taken 7.501412824789683\nRunning Epoch 10...................\nTrain Batch       1 Loss : 0.6703790426254272 Time Taken : 0.011794507503509521 \nTrain Batch      21 Loss : 0.6298780838648478 Time Taken : 0.2384276270866394 \nTrain Batch      41 Loss : 0.6367444970258852 Time Taken : 0.23919257322947185 \nTest Batch       1 Loss : 0.5706556439399719\nFor Epoch      10 Train Loss 0.643819 Train AUC 0.6692250372578242 Val Loss 0.7282689000879016 Val AUC 0.5201923076923076 \nFor Epoch      10 Time Taken 8.272278535366059\n['T2w_loss0.655_auc0.706.pth', 'FLAIR_loss0.649_auc0.704.pth', 'T1wCE_loss0.674_auc0.648.pth', 'T1w_loss0.666_auc0.641.pth']\n","output_type":"stream"}]},{"cell_type":"code","source":"def predict(modelfile, df, mri_type, split):\n    \n    print(\"Predict:\", modelfile, mri_type, df.shape)\n    df.loc[:,\"MRI_Type\"] = mri_type\n    \n    data_retriever = MRIScanDataset(\n        df.index.values, \n        mri_type=df[\"MRI_Type\"].values,\n        split=split\n    )\n\n    data_loader = DataLoader(\n        data_retriever,\n        batch_size=8,\n        shuffle=False,\n        num_workers=8,\n    )\n   \n    model = CNNModel()\n    model.to(device)\n    \n    model.load_state_dict(torch.load(modelfile))\n    model.eval()\n    \n    y_pred = []\n    ids = []\n\n    for e, batch in enumerate(data_loader,1):\n        \n        print(f\"{e}/{len(data_loader)}\", end=\"\\r\")\n        with torch.no_grad():\n            tmp_pred = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            if tmp_pred.size == 1:\n                y_pred.append(tmp_pred)\n            else:\n                y_pred.extend(tmp_pred.tolist())\n            batch_id_list = list(batch[\"id\"])\n            batch_id_list = [x.split('.')[0] for x in batch_id_list]\n#             print(batch_id_list)\n            ids.extend(batch_id_list)\n            \n    preddf = pd.DataFrame({\"BraTS21ID\": ids, \"MGMT_value\": y_pred}) \n    preddf = preddf.set_index(\"BraTS21ID\")\n    return preddf","metadata":{"execution":{"iopub.status.busy":"2021-09-15T19:20:27.252604Z","iopub.execute_input":"2021-09-15T19:20:27.252952Z","iopub.status.idle":"2021-09-15T19:20:27.263761Z","shell.execute_reply.started":"2021-09-15T19:20:27.252921Z","shell.execute_reply":"2021-09-15T19:20:27.262681Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"modelfiles","metadata":{"execution":{"iopub.status.busy":"2021-09-15T19:20:27.571665Z","iopub.execute_input":"2021-09-15T19:20:27.571992Z","iopub.status.idle":"2021-09-15T19:20:27.577895Z","shell.execute_reply.started":"2021-09-15T19:20:27.571961Z","shell.execute_reply":"2021-09-15T19:20:27.576863Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"['T2w_loss0.655_auc0.706.pth',\n 'FLAIR_loss0.649_auc0.704.pth',\n 'T1wCE_loss0.674_auc0.648.pth',\n 'T1w_loss0.666_auc0.641.pth']"},"metadata":{}}]},{"cell_type":"code","source":"mri_types = ['T2w', 'FLAIR', 'T1wCE', 'T1w']\n# df_valid = df_valid.set_index(\"BraTS21ID\")\n\nfor m, mtype in zip(modelfiles,  mri_types):\n    pred = predict(m, df_valid, mtype, \"train\")\n    df_valid[f\"MGMT_pred_{mtype}\"] = pred\n    \ndf_valid.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T19:20:27.989675Z","iopub.execute_input":"2021-09-15T19:20:27.989985Z","iopub.status.idle":"2021-09-15T19:20:50.461817Z","shell.execute_reply.started":"2021-09-15T19:20:27.989955Z","shell.execute_reply":"2021-09-15T19:20:50.460882Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Predict: T2w_loss0.655_auc0.706.pth T2w (117, 6)\nPredict: FLAIR_loss0.649_auc0.704.pth FLAIR (117, 6)\nPredict: T1wCE_loss0.674_auc0.648.pth T1wCE (117, 6)\nPredict: T1w_loss0.666_auc0.641.pth T1w (117, 6)\n15/15\r","output_type":"stream"},{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"           MGMT_value MRI_Type  MGMT_pred_T2w  MGMT_pred_FLAIR  \\\nBraTS21ID                                                        \n00418               0      T1w       0.477596         0.644198   \n00836               0      T1w       0.457938         0.426843   \n00705               1      T1w       0.493994         0.585502   \n00078               1      T1w       0.598755         0.579366   \n00062               1      T1w       0.670807         0.601613   \n\n           MGMT_pred_T1wCE  MGMT_pred_T1w  \nBraTS21ID                                  \n00418             0.335624       0.530639  \n00836             0.484292       0.544154  \n00705             0.542805       0.567514  \n00078             0.535969       0.599698  \n00062             0.534775       0.559082  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MGMT_value</th>\n      <th>MRI_Type</th>\n      <th>MGMT_pred_T2w</th>\n      <th>MGMT_pred_FLAIR</th>\n      <th>MGMT_pred_T1wCE</th>\n      <th>MGMT_pred_T1w</th>\n    </tr>\n    <tr>\n      <th>BraTS21ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>00418</th>\n      <td>0</td>\n      <td>T1w</td>\n      <td>0.477596</td>\n      <td>0.644198</td>\n      <td>0.335624</td>\n      <td>0.530639</td>\n    </tr>\n    <tr>\n      <th>00836</th>\n      <td>0</td>\n      <td>T1w</td>\n      <td>0.457938</td>\n      <td>0.426843</td>\n      <td>0.484292</td>\n      <td>0.544154</td>\n    </tr>\n    <tr>\n      <th>00705</th>\n      <td>1</td>\n      <td>T1w</td>\n      <td>0.493994</td>\n      <td>0.585502</td>\n      <td>0.542805</td>\n      <td>0.567514</td>\n    </tr>\n    <tr>\n      <th>00078</th>\n      <td>1</td>\n      <td>T1w</td>\n      <td>0.598755</td>\n      <td>0.579366</td>\n      <td>0.535969</td>\n      <td>0.599698</td>\n    </tr>\n    <tr>\n      <th>00062</th>\n      <td>1</td>\n      <td>T1w</td>\n      <td>0.670807</td>\n      <td>0.601613</td>\n      <td>0.534775</td>\n      <td>0.559082</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_valid['avg_pred'] = df_valid[['MGMT_pred_FLAIR', 'MGMT_pred_T1w', 'MGMT_pred_T1wCE', 'MGMT_pred_T2w']].mean(axis =1)\nroc_auc_score(df_valid['MGMT_value'], df_valid['avg_pred'])","metadata":{"execution":{"iopub.status.busy":"2021-09-15T19:21:02.447778Z","iopub.execute_input":"2021-09-15T19:21:02.448149Z","iopub.status.idle":"2021-09-15T19:21:02.465503Z","shell.execute_reply.started":"2021-09-15T19:21:02.448115Z","shell.execute_reply":"2021-09-15T19:21:02.464325Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"0.7249266862170087"},"metadata":{}}]},{"cell_type":"code","source":"weights = [0.706, 0.704, 0.648, 0.641]\nweights = [i/sum(weights) for i in weights]\nweights","metadata":{"execution":{"iopub.status.busy":"2021-09-15T19:21:55.398756Z","iopub.execute_input":"2021-09-15T19:21:55.399089Z","iopub.status.idle":"2021-09-15T19:21:55.408440Z","shell.execute_reply.started":"2021-09-15T19:21:55.399061Z","shell.execute_reply":"2021-09-15T19:21:55.407415Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"[0.2615783623564283,\n 0.2608373471656169,\n 0.2400889218228974,\n 0.23749536865505744]"},"metadata":{}}]},{"cell_type":"code","source":"df_valid['weight_avg_pred'] = df_valid['MGMT_pred_T2w'] * weights[0] + df_valid['MGMT_pred_FLAIR'] * weights[1] + df_valid['MGMT_pred_T1wCE'] * weights[2] + df_valid['MGMT_pred_T1w'] * weights[3]\n    \nroc_auc_score(df_valid['MGMT_value'], df_valid['weight_avg_pred'])","metadata":{"execution":{"iopub.status.busy":"2021-09-15T19:22:52.797594Z","iopub.execute_input":"2021-09-15T19:22:52.797945Z","iopub.status.idle":"2021-09-15T19:22:52.919312Z","shell.execute_reply.started":"2021-09-15T19:22:52.797913Z","shell.execute_reply":"2021-09-15T19:22:52.918528Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"0.7243401759530791"},"metadata":{}}]},{"cell_type":"code","source":"submission = pd.read_csv(f\"{data_directory}/sample_submission.csv\", index_col=\"BraTS21ID\")\n\nfor m, mtype in zip(modelfiles,  mri_types):\n    pred = predict(m, submission, mtype, split=\"test\")\n    submission[f\"MGMT_pred_{mtype}\"] = pred\n    \nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T18:03:44.493647Z","iopub.execute_input":"2021-09-08T18:03:44.494008Z","iopub.status.idle":"2021-09-08T18:05:01.147464Z","shell.execute_reply.started":"2021-09-08T18:03:44.493978Z","shell.execute_reply":"2021-09-08T18:05:01.146545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['MGMT_value'] = submission[['MGMT_pred_FLAIR', 'MGMT_pred_T1w', 'MGMT_pred_T1wCE', 'MGMT_pred_T2w']].mean(axis =1)\nsubmission['MGMT_value'].to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-08T18:07:46.830381Z","iopub.execute_input":"2021-09-08T18:07:46.830786Z","iopub.status.idle":"2021-09-08T18:07:46.851226Z","shell.execute_reply.started":"2021-09-08T18:07:46.830747Z","shell.execute_reply":"2021-09-08T18:07:46.850446Z"},"trusted":true},"execution_count":null,"outputs":[]}]}